{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Reference - https://github.com/DSC-SCH/Determination-of-the-Status-of-Nuclear-Power-Plants/issues/6\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import multiprocessing # 여러 개의 일꾼 (cpu)들에게 작업을 분산시키는 역할\n",
    "from multiprocessing import Pool \n",
    "from functools import partial # 함수가 받는 인자들 중 몇개를 고정 시켜서 새롭게 파생된 함수를 형성하는 역할\n",
    "from data_loader_2 import data_loader_v2 # 자체적으로 만든 data loader version 2.0 ([데이콘 15회 대회] 데이터 설명 및 데이터 불러오기 영상 참조)\n",
    "\n",
    "# keras\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers, Sequential\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "\n",
    "import joblib # 모델을 저장하고 불러오는 역할\n",
    "\n",
    "train_folder = 'data/train/'\n",
    "test_folder = 'data/test/'\n",
    "train_label_path = 'data/train_label.csv'\n",
    "\n",
    "train_list = os.listdir(train_folder)\n",
    "test_list = os.listdir(test_folder)\n",
    "train_label = pd.read_csv(train_label_path, index_col=0)\n",
    "\n",
    "\n",
    "def data_loader_all_v2(func, files, folder='', train_label=None, event_time=10, nrows=60):   \n",
    "    func_fixed = partial(func, folder=folder, train_label=train_label, event_time=event_time, nrows=nrows)     \n",
    "    if __name__ == '__main__':\n",
    "        pool = Pool(processes=multiprocessing.cpu_count()) \n",
    "        df_list = list(pool.imap(func_fixed, files)) \n",
    "        pool.close()\n",
    "        pool.join()        \n",
    "    combined_df = pd.concat(df_list)    \n",
    "    return combined_df\n",
    "\n",
    "train = data_loader_all_v2(data_loader_v2, train_list, folder=train_folder, \n",
    "                        train_label=train_label, event_time=10, nrows=60)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0000</th>\n",
       "      <th>V0001</th>\n",
       "      <th>V0002</th>\n",
       "      <th>V0003</th>\n",
       "      <th>V0004</th>\n",
       "      <th>V0005</th>\n",
       "      <th>V0006</th>\n",
       "      <th>V0007</th>\n",
       "      <th>V0008</th>\n",
       "      <th>V0009</th>\n",
       "      <th>...</th>\n",
       "      <th>V5112</th>\n",
       "      <th>V5113</th>\n",
       "      <th>V5114</th>\n",
       "      <th>V5115</th>\n",
       "      <th>V5116</th>\n",
       "      <th>V5117</th>\n",
       "      <th>V5118</th>\n",
       "      <th>V5119</th>\n",
       "      <th>V5120</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>30.472197</td>\n",
       "      <td>8.695875</td>\n",
       "      <td>8.703739</td>\n",
       "      <td>8.709477</td>\n",
       "      <td>8.711114</td>\n",
       "      <td>200.381358</td>\n",
       "      <td>159.282182</td>\n",
       "      <td>-5.018619e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>30.451815</td>\n",
       "      <td>8.635427</td>\n",
       "      <td>8.705436</td>\n",
       "      <td>8.699428</td>\n",
       "      <td>8.711520</td>\n",
       "      <td>181.601175</td>\n",
       "      <td>156.666622</td>\n",
       "      <td>6.360338e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000572</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>30.464503</td>\n",
       "      <td>8.743024</td>\n",
       "      <td>8.725929</td>\n",
       "      <td>8.671431</td>\n",
       "      <td>8.743335</td>\n",
       "      <td>198.761704</td>\n",
       "      <td>191.961581</td>\n",
       "      <td>1.067647e-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>30.483019</td>\n",
       "      <td>8.752263</td>\n",
       "      <td>8.711617</td>\n",
       "      <td>8.776546</td>\n",
       "      <td>8.703115</td>\n",
       "      <td>169.724555</td>\n",
       "      <td>177.933862</td>\n",
       "      <td>-5.364949e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001408</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>30.473983</td>\n",
       "      <td>8.740589</td>\n",
       "      <td>8.692430</td>\n",
       "      <td>8.740275</td>\n",
       "      <td>8.717582</td>\n",
       "      <td>186.863251</td>\n",
       "      <td>170.349628</td>\n",
       "      <td>-1.922528e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V0000     V0001     V0002     V0003     V0004       V0005  \\\n",
       "545  30.472197  8.695875  8.703739  8.709477  8.711114  200.381358   \n",
       "545  30.451815  8.635427  8.705436  8.699428  8.711520  181.601175   \n",
       "545  30.464503  8.743024  8.725929  8.671431  8.743335  198.761704   \n",
       "545  30.483019  8.752263  8.711617  8.776546  8.703115  169.724555   \n",
       "545  30.473983  8.740589  8.692430  8.740275  8.717582  186.863251   \n",
       "\n",
       "          V0006         V0007  V0008     V0009  ...  V5112  V5113  V5114  \\\n",
       "545  159.282182 -5.018619e-19    0.0  0.001439  ...    1.0    1.0    1.0   \n",
       "545  156.666622  6.360338e-19    0.0 -0.000572  ...    1.0    1.0    1.0   \n",
       "545  191.961581  1.067647e-20    0.0  0.000346  ...    1.0    1.0    1.0   \n",
       "545  177.933862 -5.364949e-19    0.0 -0.001408  ...    1.0    1.0    1.0   \n",
       "545  170.349628 -1.922528e-19    0.0  0.001069  ...    1.0    1.0    1.0   \n",
       "\n",
       "     V5115  V5116  V5117     V5118  V5119  V5120  label  \n",
       "545   60.0    0.0    0.0 -0.000002   85.4    0.0     20  \n",
       "545   60.0    0.0    0.0  0.000003   85.4    0.0     20  \n",
       "545   60.0    0.0    0.0 -0.000028   85.4    0.0     20  \n",
       "545   60.0    0.0    0.0 -0.000009   85.4    0.0     20  \n",
       "545   60.0    0.0    0.0  0.000010   85.4    0.0     20  \n",
       "\n",
       "[5 rows x 5122 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41400, 5122)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "def unet(input_size, output_size):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(16, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(inputs)\n",
    "    conv1 = Conv2D(16, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(conv1)\n",
    "    batch_norm = BatchNormalization(axis = -1)(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(batch_norm)\n",
    "    \n",
    "    conv2 = Conv2D(32, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(pool1)\n",
    "    conv2 = Conv2D(32, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(conv2)\n",
    "    batch_norm = BatchNormalization(axis = -1)(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(batch_norm)\n",
    "    \n",
    "    conv3 = Conv2D(64, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(pool2)\n",
    "    conv3 = Conv2D(64, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(conv3)\n",
    "    batch_norm = BatchNormalization(axis = -1)(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(batch_norm)\n",
    "    \n",
    "    conv4 = Conv2D(128, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(pool3)\n",
    "    conv4 = Conv2D(128, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(conv4)\n",
    "    batch_norm = BatchNormalization(axis = -1)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(batch_norm)\n",
    "    \n",
    "    conv5 = Conv2D(256, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(pool4)\n",
    "    conv5 = Conv2D(256, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(conv5)\n",
    "    batch_norm = BatchNormalization(axis = -1)(conv5)\n",
    "\n",
    "    up6 = Conv2D(128, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(UpSampling2D(size=(2, 2), data_format=\"channels_last\")(batch_norm))\n",
    "    merge6 = concatenate([conv4, up6], axis=3)\n",
    "    conv6 = Conv2D(128, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(merge6)\n",
    "    conv6 = Conv2D(128, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(conv6)\n",
    "    \n",
    "    up7 = Conv2D(64, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(UpSampling2D(size=(2, 2), data_format=\"channels_last\")(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(64, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(merge7)\n",
    "    conv7 = Conv2D(64, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(conv7)\n",
    "    \n",
    "    up8 = Conv2D(32, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(UpSampling2D(size=(2, 2), data_format=\"channels_last\")(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(32, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(merge8)\n",
    "    conv8 = Conv2D(32, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(conv8)\n",
    "    \n",
    "    up9 = Conv2D(16, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(UpSampling2D(size=(2,2), data_format=\"channels_last\")(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(16, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(merge9)\n",
    "    conv9 = Conv2D(16, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\", data_format=\"channels_last\")(conv9)\n",
    "    \n",
    "    conv10 = Conv2D(output_size, activation=\"sigmoid\", data_format=\"channels_last\")(conv9)\n",
    "    \n",
    "    model = Model(input=inputs, output=conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V0000', 'V0001', 'V0002', 'V0003', 'V0004', 'V0005', 'V0006', 'V0007',\n",
       "       'V0008', 'V0009',\n",
       "       ...\n",
       "       'V5112', 'V5113', 'V5114', 'V5115', 'V5116', 'V5117', 'V5118', 'V5119',\n",
       "       'V5120', 'label'],\n",
       "      dtype='object', length=5122)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop([\"label\"], axis=1)\n",
    "y_train = train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41400, 5121, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input size 확인.\n",
    "rows, cols = X_train.shape\n",
    "input_size = (rows ,cols, 1)\n",
    "output_size = len(set(y_train)) + 1 \n",
    "\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 5175, 640, 128), (None, 5174, 640, 128)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-e1d4f1450701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-2a1142c0ba29>\u001b[0m in \u001b[0;36munet\u001b[0;34m(input_size, output_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mup6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"he_normal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"channels_last\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUpSampling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"channels_last\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmerge6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mconv6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"he_normal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"channels_last\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mconv6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"he_normal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"channels_last\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \"\"\"\n\u001b[0;32m--> 649\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    360\u001b[0m                              \u001b[0;34m'inputs with matching shapes '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                              \u001b[0;34m'except for the concat axis. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                              'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 5175, 640, 128), (None, 5174, 640, 128)]"
     ]
    }
   ],
   "source": [
    "# input size 확인.\n",
    "rows, cols = X_train.shape\n",
    "input_size = (rows ,cols, 1)\n",
    "output_size = len(set(y_train)) + 1 \n",
    "\n",
    "model = unet(input_size, output_size)\n",
    "\n",
    "model.fit(X_trian, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
